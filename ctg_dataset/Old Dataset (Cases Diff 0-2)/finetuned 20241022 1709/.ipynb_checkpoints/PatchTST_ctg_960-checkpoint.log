Args in experiment:
Namespace(activation='relu', affine=0, batch_size=48, c_out=1, checkpoints='./checkpoints/ctg', d_ff=128, d_layers=1, d_model=512, data='CTG', dec_in=2, decomposition=0, des='Exp', devices='0,1,2', distil=True, do_predict=False, dropout=0.1, e_layers=6, embed='timeF', embed_type=0, enc_in=2, factor=1, fc_dropout=0.4, features='M', freq='h', gpu=0, head_dropout=0.2, individual=0, is_optuna=False, is_training=1, itr=1, kernel_size=15, learning_rate=0.0001, loss='cross_entropy', lradj='type3', model='PatchTST', model_id='ctg_960', moving_avg=25, n_heads=4, num_classes=2, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=25, pct_start=0.3, pre_train_dataset_path='../ctg_dataset/Old Dataset (Cases Diff 3-7)', random_seed=2021, revin=1, root_path='./dataset/', seq_len=960, stride=16, subtract_last=0, target='OT', test_flop=False, train_dataset_path='../ctg_dataset/Old Dataset (Cases Diff 0-2)', train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : ctg_960_PatchTST_CTG_sl960_nc2_dm512_nh4_el6_df128_fc1_Exp>>>>>>>>>>>>>>>>>>>>>>>>>>
Dataset loaded and preprocessed.
train set size: 12448
Dataset loaded and preprocessed.
val set size: 3107
Dataset loaded and preprocessed.
test set size: 3107
Loading pre-trained model from ../ctg_dataset/Old Dataset (Cases Diff 3-7)/trained 20241019 0209/checkpoint.pth for fine-tuning...
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
No layers are frozen for finetuning.
Testing the pretrained model on the new dataset before fine-tuning...
Dataset loaded and preprocessed.
test set size: 3107
loading model
Accuracy: 0.7570003218538783, AUC: 0.7245658463487996, Sensitivity: 0.4607104413347686, Specificity: 0.8833792470156107, PPV: 0.6275659824046921, NPV: 0.7934020618556701, F1: 0.5313469894475481
Trainable parameters after freezing layers: ['model.backbone.W_pos', 'model.backbone.W_P.weight', 'model.backbone.W_P.bias', 'model.backbone.encoder.layers.0.self_attn.W_Q.weight', 'model.backbone.encoder.layers.0.self_attn.W_Q.bias', 'model.backbone.encoder.layers.0.self_attn.W_K.weight', 'model.backbone.encoder.layers.0.self_attn.W_K.bias', 'model.backbone.encoder.layers.0.self_attn.W_V.weight', 'model.backbone.encoder.layers.0.self_attn.W_V.bias', 'model.backbone.encoder.layers.0.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.0.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.0.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.0.norm_attn.1.weight', 'model.backbone.encoder.layers.0.norm_attn.1.bias', 'model.backbone.encoder.layers.0.ff.0.weight', 'model.backbone.encoder.layers.0.ff.0.bias', 'model.backbone.encoder.layers.0.ff.3.weight', 'model.backbone.encoder.layers.0.ff.3.bias', 'model.backbone.encoder.layers.0.norm_ffn.1.weight', 'model.backbone.encoder.layers.0.norm_ffn.1.bias', 'model.backbone.encoder.layers.1.self_attn.W_Q.weight', 'model.backbone.encoder.layers.1.self_attn.W_Q.bias', 'model.backbone.encoder.layers.1.self_attn.W_K.weight', 'model.backbone.encoder.layers.1.self_attn.W_K.bias', 'model.backbone.encoder.layers.1.self_attn.W_V.weight', 'model.backbone.encoder.layers.1.self_attn.W_V.bias', 'model.backbone.encoder.layers.1.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.1.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.1.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.1.norm_attn.1.weight', 'model.backbone.encoder.layers.1.norm_attn.1.bias', 'model.backbone.encoder.layers.1.ff.0.weight', 'model.backbone.encoder.layers.1.ff.0.bias', 'model.backbone.encoder.layers.1.ff.3.weight', 'model.backbone.encoder.layers.1.ff.3.bias', 'model.backbone.encoder.layers.1.norm_ffn.1.weight', 'model.backbone.encoder.layers.1.norm_ffn.1.bias', 'model.backbone.encoder.layers.2.self_attn.W_Q.weight', 'model.backbone.encoder.layers.2.self_attn.W_Q.bias', 'model.backbone.encoder.layers.2.self_attn.W_K.weight', 'model.backbone.encoder.layers.2.self_attn.W_K.bias', 'model.backbone.encoder.layers.2.self_attn.W_V.weight', 'model.backbone.encoder.layers.2.self_attn.W_V.bias', 'model.backbone.encoder.layers.2.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.2.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.2.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.2.norm_attn.1.weight', 'model.backbone.encoder.layers.2.norm_attn.1.bias', 'model.backbone.encoder.layers.2.ff.0.weight', 'model.backbone.encoder.layers.2.ff.0.bias', 'model.backbone.encoder.layers.2.ff.3.weight', 'model.backbone.encoder.layers.2.ff.3.bias', 'model.backbone.encoder.layers.2.norm_ffn.1.weight', 'model.backbone.encoder.layers.2.norm_ffn.1.bias', 'model.backbone.encoder.layers.3.self_attn.W_Q.weight', 'model.backbone.encoder.layers.3.self_attn.W_Q.bias', 'model.backbone.encoder.layers.3.self_attn.W_K.weight', 'model.backbone.encoder.layers.3.self_attn.W_K.bias', 'model.backbone.encoder.layers.3.self_attn.W_V.weight', 'model.backbone.encoder.layers.3.self_attn.W_V.bias', 'model.backbone.encoder.layers.3.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.3.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.3.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.3.norm_attn.1.weight', 'model.backbone.encoder.layers.3.norm_attn.1.bias', 'model.backbone.encoder.layers.3.ff.0.weight', 'model.backbone.encoder.layers.3.ff.0.bias', 'model.backbone.encoder.layers.3.ff.3.weight', 'model.backbone.encoder.layers.3.ff.3.bias', 'model.backbone.encoder.layers.3.norm_ffn.1.weight', 'model.backbone.encoder.layers.3.norm_ffn.1.bias', 'model.backbone.encoder.layers.4.self_attn.W_Q.weight', 'model.backbone.encoder.layers.4.self_attn.W_Q.bias', 'model.backbone.encoder.layers.4.self_attn.W_K.weight', 'model.backbone.encoder.layers.4.self_attn.W_K.bias', 'model.backbone.encoder.layers.4.self_attn.W_V.weight', 'model.backbone.encoder.layers.4.self_attn.W_V.bias', 'model.backbone.encoder.layers.4.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.4.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.4.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.4.norm_attn.1.weight', 'model.backbone.encoder.layers.4.norm_attn.1.bias', 'model.backbone.encoder.layers.4.ff.0.weight', 'model.backbone.encoder.layers.4.ff.0.bias', 'model.backbone.encoder.layers.4.ff.3.weight', 'model.backbone.encoder.layers.4.ff.3.bias', 'model.backbone.encoder.layers.4.norm_ffn.1.weight', 'model.backbone.encoder.layers.4.norm_ffn.1.bias', 'model.backbone.encoder.layers.5.self_attn.W_Q.weight', 'model.backbone.encoder.layers.5.self_attn.W_Q.bias', 'model.backbone.encoder.layers.5.self_attn.W_K.weight', 'model.backbone.encoder.layers.5.self_attn.W_K.bias', 'model.backbone.encoder.layers.5.self_attn.W_V.weight', 'model.backbone.encoder.layers.5.self_attn.W_V.bias', 'model.backbone.encoder.layers.5.self_attn.sdp_attn.scale', 'model.backbone.encoder.layers.5.self_attn.to_out.0.weight', 'model.backbone.encoder.layers.5.self_attn.to_out.0.bias', 'model.backbone.encoder.layers.5.norm_attn.1.weight', 'model.backbone.encoder.layers.5.norm_attn.1.bias', 'model.backbone.encoder.layers.5.ff.0.weight', 'model.backbone.encoder.layers.5.ff.0.bias', 'model.backbone.encoder.layers.5.ff.3.weight', 'model.backbone.encoder.layers.5.ff.3.bias', 'model.backbone.encoder.layers.5.norm_ffn.1.weight', 'model.backbone.encoder.layers.5.norm_ffn.1.bias', 'model.head.linear.weight', 'model.head.linear.bias', 'classification_head.weight', 'classification_head.bias']
	iters: 100, epoch: 1 | loss: 0.6899860
	speed: 0.1892s/iter; left time: 4899.8397s
	iters: 200, epoch: 1 | loss: 0.6535728
	speed: 0.0329s/iter; left time: 849.2874s
Epoch: 1 cost time: 25.202330589294434
Epoch: 1, Steps: 260 | Train Loss: 0.6688652 Vali Loss: 0.6680103 Vali AUC: 0.7240454
Validation loss decreased (inf --> 0.668010).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6594672
	speed: 0.5305s/iter; left time: 13603.2941s
	iters: 200, epoch: 2 | loss: 0.6740026
	speed: 0.0329s/iter; left time: 841.2101s
Epoch: 2 cost time: 25.196329832077026
Epoch: 2, Steps: 260 | Train Loss: 0.6792310 Vali Loss: 0.6772995 Vali AUC: 0.6717572
EarlyStopping counter: 1 out of 25
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.6576769
	speed: 0.5291s/iter; left time: 13429.0570s
	iters: 200, epoch: 3 | loss: 0.7030107
	speed: 0.0329s/iter; left time: 832.2067s
Epoch: 3 cost time: 25.081729888916016
Epoch: 3, Steps: 260 | Train Loss: 0.6768864 Vali Loss: 0.6875160 Vali AUC: 0.6550677
EarlyStopping counter: 2 out of 25
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.6886593
	speed: 0.5307s/iter; left time: 13332.4828s
	iters: 200, epoch: 4 | loss: 0.6684648
	speed: 0.0329s/iter; left time: 824.0939s
Epoch: 4 cost time: 25.203311920166016
Epoch: 4, Steps: 260 | Train Loss: 0.6834665 Vali Loss: 0.6769164 Vali AUC: 0.6796068
EarlyStopping counter: 3 out of 25
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.7181923
	speed: 0.5293s/iter; left time: 13158.6793s
	iters: 200, epoch: 5 | loss: 0.7535714
	speed: 0.0329s/iter; left time: 814.5399s
Epoch: 5 cost time: 25.18790864944458
Epoch: 5, Steps: 260 | Train Loss: 0.6791940 Vali Loss: 0.6739779 Vali AUC: 0.6953939
EarlyStopping counter: 4 out of 25
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.7321338
	speed: 0.5309s/iter; left time: 13060.3723s
	iters: 200, epoch: 6 | loss: 0.6548350
	speed: 0.0329s/iter; left time: 806.4090s
Epoch: 6 cost time: 25.195507526397705
Epoch: 6, Steps: 260 | Train Loss: 0.6756002 Vali Loss: 0.6756772 Vali AUC: 0.7161729
EarlyStopping counter: 5 out of 25
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.6800888
	speed: 0.5305s/iter; left time: 12912.1161s
	iters: 200, epoch: 7 | loss: 0.6300096
	speed: 0.0329s/iter; left time: 798.7179s
Epoch: 7 cost time: 25.148969411849976
Epoch: 7, Steps: 260 | Train Loss: 0.6724147 Vali Loss: 0.6716949 Vali AUC: 0.7016503
EarlyStopping counter: 6 out of 25
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.6901358
	speed: 0.5308s/iter; left time: 12781.7628s
	iters: 200, epoch: 8 | loss: 0.6742949
	speed: 0.0329s/iter; left time: 788.8368s
Epoch: 8 cost time: 25.2763454914093
Epoch: 8, Steps: 260 | Train Loss: 0.6765591 Vali Loss: 0.6695151 Vali AUC: 0.7078012
EarlyStopping counter: 7 out of 25
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.6489968
	speed: 0.5309s/iter; left time: 12647.7234s
	iters: 200, epoch: 9 | loss: 0.6697302
	speed: 0.0329s/iter; left time: 780.6066s
Epoch: 9 cost time: 25.17878246307373
Epoch: 9, Steps: 260 | Train Loss: 0.6735112 Vali Loss: 0.6708067 Vali AUC: 0.7307847
EarlyStopping counter: 8 out of 25
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.7106417
	speed: 0.5317s/iter; left time: 12526.7227s
	iters: 200, epoch: 10 | loss: 0.6532235
	speed: 0.0329s/iter; left time: 772.7341s
Epoch: 10 cost time: 25.262388467788696
Epoch: 10, Steps: 260 | Train Loss: 0.6732841 Vali Loss: 0.6685022 Vali AUC: 0.7143897
EarlyStopping counter: 9 out of 25
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.6511998
	speed: 0.5299s/iter; left time: 12347.2441s
	iters: 200, epoch: 11 | loss: 0.6635393
	speed: 0.0329s/iter; left time: 763.1133s
Epoch: 11 cost time: 25.2412371635437
Epoch: 11, Steps: 260 | Train Loss: 0.6745434 Vali Loss: 0.6662409 Vali AUC: 0.7301600
Validation loss decreased (0.668010 --> 0.666241).  Saving model ...
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.6323027
	speed: 0.5313s/iter; left time: 12242.1755s
	iters: 200, epoch: 12 | loss: 0.6514975
	speed: 0.0329s/iter; left time: 754.7946s
Epoch: 12 cost time: 25.187040090560913
Epoch: 12, Steps: 260 | Train Loss: 0.6726774 Vali Loss: 0.6680677 Vali AUC: 0.7260935
EarlyStopping counter: 1 out of 25
Updating learning rate to 3.874204890000001e-05
	iters: 100, epoch: 13 | loss: 0.7037479
	speed: 0.5314s/iter; left time: 12106.5490s
	iters: 200, epoch: 13 | loss: 0.6800548
	speed: 0.0328s/iter; left time: 744.8611s
Epoch: 13 cost time: 25.161039352416992
Epoch: 13, Steps: 260 | Train Loss: 0.6721328 Vali Loss: 0.6682952 Vali AUC: 0.7220801
EarlyStopping counter: 2 out of 25
Updating learning rate to 3.486784401000001e-05
	iters: 100, epoch: 14 | loss: 0.7148874
	speed: 0.5315s/iter; left time: 11969.4530s
	iters: 200, epoch: 14 | loss: 0.6882386
	speed: 0.0329s/iter; left time: 737.9872s
Epoch: 14 cost time: 25.18118929862976
Epoch: 14, Steps: 260 | Train Loss: 0.6744932 Vali Loss: 0.6682388 Vali AUC: 0.7322644
EarlyStopping counter: 3 out of 25
Updating learning rate to 3.138105960900001e-05
	iters: 100, epoch: 15 | loss: 0.6442472
	speed: 0.5317s/iter; left time: 11835.9563s
	iters: 200, epoch: 15 | loss: 0.6426389
	speed: 0.0329s/iter; left time: 728.7371s
Epoch: 15 cost time: 25.32360816001892
Epoch: 15, Steps: 260 | Train Loss: 0.6714417 Vali Loss: 0.6665588 Vali AUC: 0.7394487
EarlyStopping counter: 4 out of 25
Updating learning rate to 2.824295364810001e-05
	iters: 100, epoch: 16 | loss: 0.6599598
	speed: 0.5326s/iter; left time: 11716.7114s
	iters: 200, epoch: 16 | loss: 0.6753640
	speed: 0.0329s/iter; left time: 721.0590s
Epoch: 16 cost time: 25.275381565093994
Epoch: 16, Steps: 260 | Train Loss: 0.6717616 Vali Loss: 0.6673086 Vali AUC: 0.7411780
EarlyStopping counter: 5 out of 25
Updating learning rate to 2.541865828329001e-05
	iters: 100, epoch: 17 | loss: 0.6894516
	speed: 0.5335s/iter; left time: 11598.3357s
	iters: 200, epoch: 17 | loss: 0.6717612
	speed: 0.0329s/iter; left time: 712.7090s
Epoch: 17 cost time: 25.33513379096985
Epoch: 17, Steps: 260 | Train Loss: 0.6713676 Vali Loss: 0.6683515 Vali AUC: 0.7363247
EarlyStopping counter: 6 out of 25
Updating learning rate to 2.287679245496101e-05
	iters: 100, epoch: 18 | loss: 0.7047209
	speed: 0.5305s/iter; left time: 11394.6219s
	iters: 200, epoch: 18 | loss: 0.6973244
	speed: 0.0329s/iter; left time: 703.8966s
Epoch: 18 cost time: 25.205026865005493
Epoch: 18, Steps: 260 | Train Loss: 0.6707477 Vali Loss: 0.6670686 Vali AUC: 0.7377414
EarlyStopping counter: 7 out of 25
Updating learning rate to 2.0589113209464907e-05
	iters: 100, epoch: 19 | loss: 0.6694779
	speed: 0.5334s/iter; left time: 11319.7458s
	iters: 200, epoch: 19 | loss: 0.6521979
	speed: 0.0329s/iter; left time: 694.0253s
Epoch: 19 cost time: 25.26609182357788
Epoch: 19, Steps: 260 | Train Loss: 0.6705345 Vali Loss: 0.6672274 Vali AUC: 0.7356274
EarlyStopping counter: 8 out of 25
Updating learning rate to 1.8530201888518416e-05
	iters: 100, epoch: 20 | loss: 0.6651224
	speed: 0.5334s/iter; left time: 11181.1522s
	iters: 200, epoch: 20 | loss: 0.6518565
	speed: 0.0329s/iter; left time: 686.6404s
Epoch: 20 cost time: 25.291133403778076
Epoch: 20, Steps: 260 | Train Loss: 0.6716656 Vali Loss: 0.6688832 Vali AUC: 0.7382888
EarlyStopping counter: 9 out of 25
Updating learning rate to 1.6677181699666577e-05
	iters: 100, epoch: 21 | loss: 0.6761333
	speed: 0.5321s/iter; left time: 11015.9193s
	iters: 200, epoch: 21 | loss: 0.6714948
	speed: 0.0329s/iter; left time: 677.1975s
Epoch: 21 cost time: 25.264076471328735
Epoch: 21, Steps: 260 | Train Loss: 0.6719953 Vali Loss: 0.6673266 Vali AUC: 0.7360875
EarlyStopping counter: 10 out of 25
Updating learning rate to 1.5009463529699919e-05
	iters: 100, epoch: 22 | loss: 0.6535895
	speed: 0.5310s/iter; left time: 10853.7387s
	iters: 200, epoch: 22 | loss: 0.6431378
	speed: 0.0329s/iter; left time: 669.0908s
Epoch: 22 cost time: 25.158161401748657
Epoch: 22, Steps: 260 | Train Loss: 0.6709292 Vali Loss: 0.6680979 Vali AUC: 0.7338558
EarlyStopping counter: 11 out of 25
Updating learning rate to 1.3508517176729929e-05
	iters: 100, epoch: 23 | loss: 0.6789393
	speed: 0.5316s/iter; left time: 10728.7598s
	iters: 200, epoch: 23 | loss: 0.6852228
	speed: 0.0329s/iter; left time: 660.8618s
Epoch: 23 cost time: 25.261114597320557
Epoch: 23, Steps: 260 | Train Loss: 0.6699064 Vali Loss: 0.6656846 Vali AUC: 0.7396808
Validation loss decreased (0.666241 --> 0.665685).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
	iters: 100, epoch: 24 | loss: 0.6824652
	speed: 0.5323s/iter; left time: 10603.1287s
	iters: 200, epoch: 24 | loss: 0.6820716
	speed: 0.0329s/iter; left time: 652.2403s
Epoch: 24 cost time: 25.173361778259277
Epoch: 24, Steps: 260 | Train Loss: 0.6707897 Vali Loss: 0.6661089 Vali AUC: 0.7367747
EarlyStopping counter: 1 out of 25
Updating learning rate to 1.0941898913151242e-05
	iters: 100, epoch: 25 | loss: 0.6565828
	speed: 0.5327s/iter; left time: 10473.6604s
	iters: 200, epoch: 25 | loss: 0.6956725
	speed: 0.0329s/iter; left time: 643.5570s
Epoch: 25 cost time: 25.297043323516846
Epoch: 25, Steps: 260 | Train Loss: 0.6699333 Vali Loss: 0.6666654 Vali AUC: 0.7220930
EarlyStopping counter: 2 out of 25
Updating learning rate to 9.847709021836118e-06
	iters: 100, epoch: 26 | loss: 0.6760169
	speed: 0.5323s/iter; left time: 10326.2560s
	iters: 200, epoch: 26 | loss: 0.6646848
	speed: 0.0329s/iter; left time: 635.2021s
Epoch: 26 cost time: 25.243856191635132
Epoch: 26, Steps: 260 | Train Loss: 0.6696340 Vali Loss: 0.6661796 Vali AUC: 0.7401362
EarlyStopping counter: 3 out of 25
Updating learning rate to 8.862938119652508e-06
	iters: 100, epoch: 27 | loss: 0.6243585
	speed: 0.5329s/iter; left time: 10199.2962s
	iters: 200, epoch: 27 | loss: 0.6456822
	speed: 0.0329s/iter; left time: 626.9327s
Epoch: 27 cost time: 25.283438682556152
Epoch: 27, Steps: 260 | Train Loss: 0.6708552 Vali Loss: 0.6644044 Vali AUC: 0.7429763
Validation loss decreased (0.665685 --> 0.664404).  Saving model ...
Updating learning rate to 7.976644307687255e-06
	iters: 100, epoch: 28 | loss: 0.6826994
	speed: 0.5340s/iter; left time: 10082.8988s
	iters: 200, epoch: 28 | loss: 0.6902966
	speed: 0.0329s/iter; left time: 618.4702s
Epoch: 28 cost time: 25.313380002975464
Epoch: 28, Steps: 260 | Train Loss: 0.6705451 Vali Loss: 0.6648638 Vali AUC: 0.7399039
EarlyStopping counter: 1 out of 25
Updating learning rate to 7.178979876918531e-06
	iters: 100, epoch: 29 | loss: 0.6533443
	speed: 0.5325s/iter; left time: 9915.6787s
	iters: 200, epoch: 29 | loss: 0.6931343
	speed: 0.0329s/iter; left time: 609.0166s
Epoch: 29 cost time: 25.27347183227539
Epoch: 29, Steps: 260 | Train Loss: 0.6692345 Vali Loss: 0.6667672 Vali AUC: 0.7363065
EarlyStopping counter: 2 out of 25
Updating learning rate to 6.4610818892266776e-06
	iters: 100, epoch: 30 | loss: 0.6976420
	speed: 0.5336s/iter; left time: 9797.3497s
	iters: 200, epoch: 30 | loss: 0.6700656
	speed: 0.0329s/iter; left time: 600.2824s
Epoch: 30 cost time: 25.28601622581482
Epoch: 30, Steps: 260 | Train Loss: 0.6703811 Vali Loss: 0.6652780 Vali AUC: 0.7389392
EarlyStopping counter: 3 out of 25
Updating learning rate to 5.8149737003040096e-06
	iters: 100, epoch: 31 | loss: 0.7122309
	speed: 0.5327s/iter; left time: 9643.1337s
	iters: 200, epoch: 31 | loss: 0.6624734
	speed: 0.0329s/iter; left time: 592.7466s
Epoch: 31 cost time: 25.280596494674683
Epoch: 31, Steps: 260 | Train Loss: 0.6697816 Vali Loss: 0.6642877 Vali AUC: 0.7418193
Validation loss decreased (0.664404 --> 0.664288).  Saving model ...
Updating learning rate to 5.23347633027361e-06
	iters: 100, epoch: 32 | loss: 0.6617616
	speed: 0.5335s/iter; left time: 9518.8182s
	iters: 200, epoch: 32 | loss: 0.6701421
	speed: 0.0329s/iter; left time: 583.7896s
Epoch: 32 cost time: 25.275811433792114
Epoch: 32, Steps: 260 | Train Loss: 0.6691456 Vali Loss: 0.6662572 Vali AUC: 0.7333211
EarlyStopping counter: 1 out of 25
Updating learning rate to 4.710128697246249e-06
	iters: 100, epoch: 33 | loss: 0.7168324
	speed: 0.5323s/iter; left time: 9357.9217s
	iters: 200, epoch: 33 | loss: 0.6645150
	speed: 0.0329s/iter; left time: 575.2792s
Epoch: 33 cost time: 25.187264919281006
Epoch: 33, Steps: 260 | Train Loss: 0.6690179 Vali Loss: 0.6659720 Vali AUC: 0.7378386
EarlyStopping counter: 2 out of 25
Updating learning rate to 4.239115827521624e-06
	iters: 100, epoch: 34 | loss: 0.6748177
	speed: 0.5315s/iter; left time: 9206.7773s
	iters: 200, epoch: 34 | loss: 0.6770563
	speed: 0.0329s/iter; left time: 566.4854s
Epoch: 34 cost time: 25.293665647506714
Epoch: 34, Steps: 260 | Train Loss: 0.6690474 Vali Loss: 0.6653340 Vali AUC: 0.7418969
EarlyStopping counter: 3 out of 25
Updating learning rate to 3.815204244769462e-06
	iters: 100, epoch: 35 | loss: 0.6758246
	speed: 0.5328s/iter; left time: 9090.3738s
	iters: 200, epoch: 35 | loss: 0.6615618
	speed: 0.0329s/iter; left time: 558.3965s
Epoch: 35 cost time: 25.286490201950073
Epoch: 35, Steps: 260 | Train Loss: 0.6686172 Vali Loss: 0.6662628 Vali AUC: 0.7384840
EarlyStopping counter: 4 out of 25
Updating learning rate to 3.4336838202925152e-06
	iters: 100, epoch: 36 | loss: 0.7153546
	speed: 0.5328s/iter; left time: 8952.0775s
	iters: 200, epoch: 36 | loss: 0.6953486
	speed: 0.0329s/iter; left time: 549.8766s
Epoch: 36 cost time: 25.34386920928955
Epoch: 36, Steps: 260 | Train Loss: 0.6691867 Vali Loss: 0.6662237 Vali AUC: 0.7361624
EarlyStopping counter: 5 out of 25
Updating learning rate to 3.090315438263264e-06
	iters: 100, epoch: 37 | loss: 0.6396299
	speed: 0.5343s/iter; left time: 8837.5042s
	iters: 200, epoch: 37 | loss: 0.6447795
	speed: 0.0329s/iter; left time: 541.3141s
Epoch: 37 cost time: 25.355607271194458
Epoch: 37, Steps: 260 | Train Loss: 0.6689716 Vali Loss: 0.6654657 Vali AUC: 0.7367038
EarlyStopping counter: 6 out of 25
Updating learning rate to 2.7812838944369375e-06
	iters: 100, epoch: 38 | loss: 0.6600430
	speed: 0.5324s/iter; left time: 8668.4289s
	iters: 200, epoch: 38 | loss: 0.7214518
	speed: 0.0329s/iter; left time: 532.3286s
Epoch: 38 cost time: 25.277924299240112
Epoch: 38, Steps: 260 | Train Loss: 0.6693174 Vali Loss: 0.6655630 Vali AUC: 0.7375702
EarlyStopping counter: 7 out of 25
Updating learning rate to 2.503155504993244e-06
	iters: 100, epoch: 39 | loss: 0.6761718
	speed: 0.5335s/iter; left time: 8547.3534s
	iters: 200, epoch: 39 | loss: 0.7014527
	speed: 0.0329s/iter; left time: 524.4492s
Epoch: 39 cost time: 25.252310037612915
Epoch: 39, Steps: 260 | Train Loss: 0.6689235 Vali Loss: 0.6652808 Vali AUC: 0.7419305
EarlyStopping counter: 8 out of 25
Updating learning rate to 2.2528399544939195e-06
	iters: 100, epoch: 40 | loss: 0.6653038
	speed: 0.5324s/iter; left time: 8390.8783s
	iters: 200, epoch: 40 | loss: 0.6325541
	speed: 0.0329s/iter; left time: 515.2174s
Epoch: 40 cost time: 25.26586890220642
Epoch: 40, Steps: 260 | Train Loss: 0.6689226 Vali Loss: 0.6656804 Vali AUC: 0.7416661
EarlyStopping counter: 9 out of 25
Updating learning rate to 2.0275559590445276e-06
	iters: 100, epoch: 41 | loss: 0.6490334
	speed: 0.5327s/iter; left time: 8256.9170s
	iters: 200, epoch: 41 | loss: 0.6447054
	speed: 0.0329s/iter; left time: 506.7350s
Epoch: 41 cost time: 25.30978488922119
Epoch: 41, Steps: 260 | Train Loss: 0.6692644 Vali Loss: 0.6654100 Vali AUC: 0.7414835
EarlyStopping counter: 10 out of 25
Updating learning rate to 1.8248003631400751e-06
	iters: 100, epoch: 42 | loss: 0.6536002
	speed: 0.5333s/iter; left time: 8127.8691s
	iters: 200, epoch: 42 | loss: 0.6586782
	speed: 0.0329s/iter; left time: 498.1371s
Epoch: 42 cost time: 25.393717527389526
Epoch: 42, Steps: 260 | Train Loss: 0.6689593 Vali Loss: 0.6654712 Vali AUC: 0.7386869
EarlyStopping counter: 11 out of 25
Updating learning rate to 1.6423203268260676e-06
	iters: 100, epoch: 43 | loss: 0.6762999
	speed: 0.5333s/iter; left time: 7989.8400s
	iters: 200, epoch: 43 | loss: 0.6834750
	speed: 0.0329s/iter; left time: 490.0267s
Epoch: 43 cost time: 25.30806875228882
Epoch: 43, Steps: 260 | Train Loss: 0.6684970 Vali Loss: 0.6645231 Vali AUC: 0.7420187
EarlyStopping counter: 12 out of 25
Updating learning rate to 1.4780882941434609e-06
	iters: 100, epoch: 44 | loss: 0.6899002
	speed: 0.5324s/iter; left time: 7836.8709s
	iters: 200, epoch: 44 | loss: 0.6736640
	speed: 0.0328s/iter; left time: 480.2897s
Epoch: 44 cost time: 25.229602098464966
Epoch: 44, Steps: 260 | Train Loss: 0.6688964 Vali Loss: 0.6644779 Vali AUC: 0.7426014
EarlyStopping counter: 13 out of 25
Updating learning rate to 1.3302794647291146e-06
	iters: 100, epoch: 45 | loss: 0.6667489
	speed: 0.5331s/iter; left time: 7708.8875s
	iters: 200, epoch: 45 | loss: 0.6603842
	speed: 0.0329s/iter; left time: 472.7194s
Epoch: 45 cost time: 25.321210622787476
Epoch: 45, Steps: 260 | Train Loss: 0.6685665 Vali Loss: 0.6650633 Vali AUC: 0.7423138
EarlyStopping counter: 14 out of 25
Updating learning rate to 1.1972515182562034e-06
	iters: 100, epoch: 46 | loss: 0.6535758
	speed: 0.5345s/iter; left time: 7590.4864s
	iters: 200, epoch: 46 | loss: 0.6801038
	speed: 0.0329s/iter; left time: 464.3847s
Epoch: 46 cost time: 25.241766929626465
Epoch: 46, Steps: 260 | Train Loss: 0.6695412 Vali Loss: 0.6648805 Vali AUC: 0.7425695
EarlyStopping counter: 15 out of 25
Updating learning rate to 1.077526366430583e-06
	iters: 100, epoch: 47 | loss: 0.6749372
	speed: 0.5328s/iter; left time: 7427.2880s
	iters: 200, epoch: 47 | loss: 0.6427560
	speed: 0.0329s/iter; left time: 455.8165s
Epoch: 47 cost time: 25.39037275314331
Epoch: 47, Steps: 260 | Train Loss: 0.6684437 Vali Loss: 0.6649886 Vali AUC: 0.7427277
EarlyStopping counter: 16 out of 25
Updating learning rate to 9.697737297875248e-07
	iters: 100, epoch: 48 | loss: 0.6418778
	speed: 0.5342s/iter; left time: 7308.1629s
	iters: 200, epoch: 48 | loss: 0.6732292
	speed: 0.0329s/iter; left time: 447.1310s
Epoch: 48 cost time: 25.337781190872192
Epoch: 48, Steps: 260 | Train Loss: 0.6682159 Vali Loss: 0.6649115 Vali AUC: 0.7439378
EarlyStopping counter: 17 out of 25
Updating learning rate to 8.727963568087723e-07
	iters: 100, epoch: 49 | loss: 0.6205219
	speed: 0.5328s/iter; left time: 7150.4945s
	iters: 200, epoch: 49 | loss: 0.6702275
	speed: 0.0329s/iter; left time: 438.3430s
Epoch: 49 cost time: 25.273699045181274
Epoch: 49, Steps: 260 | Train Loss: 0.6681671 Vali Loss: 0.6644716 Vali AUC: 0.7430732
EarlyStopping counter: 18 out of 25
Updating learning rate to 7.855167211278951e-07
	iters: 100, epoch: 50 | loss: 0.6671225
	speed: 0.5330s/iter; left time: 7015.2686s
	iters: 200, epoch: 50 | loss: 0.6851270
	speed: 0.0329s/iter; left time: 429.9872s
Epoch: 50 cost time: 25.290877103805542
Epoch: 50, Steps: 260 | Train Loss: 0.6693745 Vali Loss: 0.6643044 Vali AUC: 0.7428033
EarlyStopping counter: 19 out of 25
Updating learning rate to 7.069650490151056e-07
	iters: 100, epoch: 51 | loss: 0.6824255
	speed: 0.5330s/iter; left time: 6875.8381s
	iters: 200, epoch: 51 | loss: 0.6664938
	speed: 0.0329s/iter; left time: 421.6407s
Epoch: 51 cost time: 25.263718843460083
Epoch: 51, Steps: 260 | Train Loss: 0.6700223 Vali Loss: 0.6654723 Vali AUC: 0.7419550
EarlyStopping counter: 20 out of 25
Updating learning rate to 6.36268544113595e-07
	iters: 100, epoch: 52 | loss: 0.6500884
	speed: 0.5332s/iter; left time: 6740.3344s
	iters: 200, epoch: 52 | loss: 0.6693611
	speed: 0.0329s/iter; left time: 413.0628s
Epoch: 52 cost time: 25.27366042137146
Epoch: 52, Steps: 260 | Train Loss: 0.6692103 Vali Loss: 0.6645662 Vali AUC: 0.7411318
EarlyStopping counter: 21 out of 25
Updating learning rate to 5.726416897022355e-07
	iters: 100, epoch: 53 | loss: 0.6709459
	speed: 0.5335s/iter; left time: 6605.4494s
	iters: 200, epoch: 53 | loss: 0.6820194
	speed: 0.0329s/iter; left time: 403.9749s
Epoch: 53 cost time: 25.369176626205444
Epoch: 53, Steps: 260 | Train Loss: 0.6695283 Vali Loss: 0.6638361 Vali AUC: 0.7440463
Validation loss decreased (0.664288 --> 0.663836).  Saving model ...
Updating learning rate to 5.15377520732012e-07
	iters: 100, epoch: 54 | loss: 0.6585864
	speed: 0.5355s/iter; left time: 6490.2956s
	iters: 200, epoch: 54 | loss: 0.6433675
	speed: 0.0329s/iter; left time: 395.9833s
Epoch: 54 cost time: 25.342265844345093
Epoch: 54, Steps: 260 | Train Loss: 0.6687031 Vali Loss: 0.6652067 Vali AUC: 0.7416404
EarlyStopping counter: 1 out of 25
Updating learning rate to 4.6383976865881085e-07
	iters: 100, epoch: 55 | loss: 0.6703197
	speed: 0.5358s/iter; left time: 6354.6745s
	iters: 200, epoch: 55 | loss: 0.6736345
	speed: 0.0329s/iter; left time: 386.7776s
Epoch: 55 cost time: 25.382025957107544
Epoch: 55, Steps: 260 | Train Loss: 0.6691061 Vali Loss: 0.6647035 Vali AUC: 0.7412455
EarlyStopping counter: 2 out of 25
Updating learning rate to 4.174557917929298e-07
	iters: 100, epoch: 56 | loss: 0.6542681
	speed: 0.5334s/iter; left time: 6188.1900s
	iters: 200, epoch: 56 | loss: 0.6718682
	speed: 0.0329s/iter; left time: 378.8572s
Epoch: 56 cost time: 25.321643114089966
Epoch: 56, Steps: 260 | Train Loss: 0.6689677 Vali Loss: 0.6651764 Vali AUC: 0.7407053
EarlyStopping counter: 3 out of 25
Updating learning rate to 3.7571021261363677e-07
	iters: 100, epoch: 57 | loss: 0.6719748
	speed: 0.5335s/iter; left time: 6050.0842s
	iters: 200, epoch: 57 | loss: 0.6815847
	speed: 0.0329s/iter; left time: 370.0763s
Epoch: 57 cost time: 25.37469220161438
Epoch: 57, Steps: 260 | Train Loss: 0.6689895 Vali Loss: 0.6643984 Vali AUC: 0.7415015
EarlyStopping counter: 4 out of 25
Updating learning rate to 3.381391913522731e-07
	iters: 100, epoch: 58 | loss: 0.6353170
	speed: 0.5345s/iter; left time: 5922.3402s
	iters: 200, epoch: 58 | loss: 0.6478026
	speed: 0.0329s/iter; left time: 361.0523s
Epoch: 58 cost time: 25.29961109161377
Epoch: 58, Steps: 260 | Train Loss: 0.6697804 Vali Loss: 0.6647171 Vali AUC: 0.7417605
EarlyStopping counter: 5 out of 25
Updating learning rate to 3.043252722170458e-07
	iters: 100, epoch: 59 | loss: 0.6495591
	speed: 0.5345s/iter; left time: 5783.8118s
	iters: 200, epoch: 59 | loss: 0.6995837
	speed: 0.0329s/iter; left time: 353.2253s
Epoch: 59 cost time: 25.409520387649536
Epoch: 59, Steps: 260 | Train Loss: 0.6687877 Vali Loss: 0.6647222 Vali AUC: 0.7434058
EarlyStopping counter: 6 out of 25
Updating learning rate to 2.7389274499534124e-07
	iters: 100, epoch: 60 | loss: 0.6491038
	speed: 0.5352s/iter; left time: 5652.2813s
	iters: 200, epoch: 60 | loss: 0.6636302
	speed: 0.0329s/iter; left time: 344.4699s
Epoch: 60 cost time: 25.38274383544922
Epoch: 60, Steps: 260 | Train Loss: 0.6683827 Vali Loss: 0.6654945 Vali AUC: 0.7415937
EarlyStopping counter: 7 out of 25
Updating learning rate to 2.465034704958071e-07
	iters: 100, epoch: 61 | loss: 0.6876428
	speed: 0.5359s/iter; left time: 5520.4327s
	iters: 200, epoch: 61 | loss: 0.6614023
	speed: 0.0328s/iter; left time: 334.7988s
Epoch: 61 cost time: 25.35900640487671
Epoch: 61, Steps: 260 | Train Loss: 0.6691504 Vali Loss: 0.6641350 Vali AUC: 0.7425026
EarlyStopping counter: 8 out of 25
Updating learning rate to 2.218531234462264e-07
	iters: 100, epoch: 62 | loss: 0.6571826
	speed: 0.5397s/iter; left time: 5419.4080s
	iters: 200, epoch: 62 | loss: 0.6575730
	speed: 0.0329s/iter; left time: 327.1452s
Epoch: 62 cost time: 25.381314992904663
Epoch: 62, Steps: 260 | Train Loss: 0.6686331 Vali Loss: 0.6652602 Vali AUC: 0.7427480
EarlyStopping counter: 9 out of 25
Updating learning rate to 1.9966781110160376e-07
	iters: 100, epoch: 63 | loss: 0.6557204
	speed: 0.5344s/iter; left time: 5227.3190s
	iters: 200, epoch: 63 | loss: 0.6747538
	speed: 0.0329s/iter; left time: 318.6564s
Epoch: 63 cost time: 25.263115406036377
Epoch: 63, Steps: 260 | Train Loss: 0.6682836 Vali Loss: 0.6650043 Vali AUC: 0.7431394
EarlyStopping counter: 10 out of 25
Updating learning rate to 1.797010299914434e-07
	iters: 100, epoch: 64 | loss: 0.6768385
	speed: 0.5373s/iter; left time: 5116.1064s
	iters: 200, epoch: 64 | loss: 0.6682875
	speed: 0.0329s/iter; left time: 310.1502s
Epoch: 64 cost time: 25.427112817764282
Epoch: 64, Steps: 260 | Train Loss: 0.6693966 Vali Loss: 0.6655386 Vali AUC: 0.7414776
EarlyStopping counter: 11 out of 25
Updating learning rate to 1.6173092699229907e-07
	iters: 100, epoch: 65 | loss: 0.6812477
	speed: 0.5347s/iter; left time: 4951.9603s
	iters: 200, epoch: 65 | loss: 0.6436675
	speed: 0.0329s/iter; left time: 301.5051s
Epoch: 65 cost time: 25.378130197525024
Epoch: 65, Steps: 260 | Train Loss: 0.6682915 Vali Loss: 0.6658853 Vali AUC: 0.7392839
EarlyStopping counter: 12 out of 25
Updating learning rate to 1.4555783429306916e-07
	iters: 100, epoch: 66 | loss: 0.6550418
	speed: 0.5374s/iter; left time: 4837.4462s
	iters: 200, epoch: 66 | loss: 0.6643693
	speed: 0.0329s/iter; left time: 292.9362s
Epoch: 66 cost time: 25.410578966140747
Epoch: 66, Steps: 260 | Train Loss: 0.6683239 Vali Loss: 0.6654460 Vali AUC: 0.7411709
EarlyStopping counter: 13 out of 25
Updating learning rate to 1.3100205086376224e-07
	iters: 100, epoch: 67 | loss: 0.6760343
	speed: 0.5372s/iter; left time: 4695.4219s
	iters: 200, epoch: 67 | loss: 0.6664976
	speed: 0.0329s/iter; left time: 284.4535s
Epoch: 67 cost time: 25.52663493156433
Epoch: 67, Steps: 260 | Train Loss: 0.6687980 Vali Loss: 0.6644904 Vali AUC: 0.7426279
EarlyStopping counter: 14 out of 25
Updating learning rate to 1.1790184577738603e-07
	iters: 100, epoch: 68 | loss: 0.6535673
	speed: 0.5353s/iter; left time: 4540.1035s
	iters: 200, epoch: 68 | loss: 0.6947311
	speed: 0.0329s/iter; left time: 275.7362s
Epoch: 68 cost time: 25.286585092544556
Epoch: 68, Steps: 260 | Train Loss: 0.6687591 Vali Loss: 0.6650142 Vali AUC: 0.7427168
EarlyStopping counter: 15 out of 25
Updating learning rate to 1.0611166119964742e-07
	iters: 100, epoch: 69 | loss: 0.6429238
	speed: 0.5352s/iter; left time: 4399.7812s
	iters: 200, epoch: 69 | loss: 0.6501353
	speed: 0.0329s/iter; left time: 267.1499s
Epoch: 69 cost time: 25.46570348739624
Epoch: 69, Steps: 260 | Train Loss: 0.6680371 Vali Loss: 0.6650089 Vali AUC: 0.7409463
EarlyStopping counter: 16 out of 25
Updating learning rate to 9.550049507968268e-08
	iters: 100, epoch: 70 | loss: 0.7017133
	speed: 0.5364s/iter; left time: 4270.2886s
	iters: 200, epoch: 70 | loss: 0.6975419
	speed: 0.0329s/iter; left time: 258.7304s
Epoch: 70 cost time: 25.437968492507935
Epoch: 70, Steps: 260 | Train Loss: 0.6697317 Vali Loss: 0.6647339 Vali AUC: 0.7420160
EarlyStopping counter: 17 out of 25
Updating learning rate to 8.595044557171442e-08
	iters: 100, epoch: 71 | loss: 0.6636177
	speed: 0.5356s/iter; left time: 4124.3970s
	iters: 200, epoch: 71 | loss: 0.6950824
	speed: 0.0329s/iter; left time: 250.0380s
Epoch: 71 cost time: 25.438645839691162
Epoch: 71, Steps: 260 | Train Loss: 0.6674642 Vali Loss: 0.6648877 Vali AUC: 0.7430104
EarlyStopping counter: 18 out of 25
Updating learning rate to 7.735540101454298e-08
	iters: 100, epoch: 72 | loss: 0.6744193
	speed: 0.5365s/iter; left time: 3991.7636s
	iters: 200, epoch: 72 | loss: 0.6528638
	speed: 0.0329s/iter; left time: 241.6937s
Epoch: 72 cost time: 25.380938291549683
Epoch: 72, Steps: 260 | Train Loss: 0.6690747 Vali Loss: 0.6653580 Vali AUC: 0.7429706
EarlyStopping counter: 19 out of 25
Updating learning rate to 6.961986091308869e-08
	iters: 100, epoch: 73 | loss: 0.6847638
	speed: 0.5369s/iter; left time: 3855.7166s
	iters: 200, epoch: 73 | loss: 0.7197484
	speed: 0.0329s/iter; left time: 232.9097s
Epoch: 73 cost time: 25.43995714187622
Epoch: 73, Steps: 260 | Train Loss: 0.6689637 Vali Loss: 0.6655162 Vali AUC: 0.7422083
EarlyStopping counter: 20 out of 25
Updating learning rate to 6.265787482177981e-08
	iters: 100, epoch: 74 | loss: 0.6377405
	speed: 0.5351s/iter; left time: 3703.5178s
	iters: 200, epoch: 74 | loss: 0.6847882
	speed: 0.0330s/iter; left time: 224.7937s
Epoch: 74 cost time: 25.51009702682495
Epoch: 74, Steps: 260 | Train Loss: 0.6683466 Vali Loss: 0.6656769 Vali AUC: 0.7412631
EarlyStopping counter: 21 out of 25
Updating learning rate to 5.639208733960184e-08
	iters: 100, epoch: 75 | loss: 0.6666741
	speed: 0.5367s/iter; left time: 3575.1848s
	iters: 200, epoch: 75 | loss: 0.6695478
	speed: 0.0329s/iter; left time: 215.9764s
Epoch: 75 cost time: 25.50406312942505
Epoch: 75, Steps: 260 | Train Loss: 0.6697818 Vali Loss: 0.6650527 Vali AUC: 0.7424588
EarlyStopping counter: 22 out of 25
Updating learning rate to 5.075287860564165e-08
	iters: 100, epoch: 76 | loss: 0.6574571
	speed: 0.5390s/iter; left time: 3450.2721s
	iters: 200, epoch: 76 | loss: 0.6612777
	speed: 0.0329s/iter; left time: 207.4063s
Epoch: 76 cost time: 25.4931058883667
Epoch: 76, Steps: 260 | Train Loss: 0.6685084 Vali Loss: 0.6646775 Vali AUC: 0.7435192
EarlyStopping counter: 23 out of 25
Updating learning rate to 4.567759074507749e-08
	iters: 100, epoch: 77 | loss: 0.7012994
	speed: 0.5369s/iter; left time: 3297.2009s
	iters: 200, epoch: 77 | loss: 0.6872236
	speed: 0.0329s/iter; left time: 198.5708s
Epoch: 77 cost time: 25.560163259506226
Epoch: 77, Steps: 260 | Train Loss: 0.6690390 Vali Loss: 0.6645980 Vali AUC: 0.7417286
EarlyStopping counter: 24 out of 25
Updating learning rate to 4.1109831670569744e-08
	iters: 100, epoch: 78 | loss: 0.7370688
	speed: 0.5384s/iter; left time: 3166.5585s
	iters: 200, epoch: 78 | loss: 0.6583930
	speed: 0.0329s/iter; left time: 190.2728s
Epoch: 78 cost time: 25.479779720306396
Epoch: 78, Steps: 260 | Train Loss: 0.6684676 Vali Loss: 0.6645588 Vali AUC: 0.7439309
EarlyStopping counter: 25 out of 25
Early stopping
>>>>>>>testing : ctg_960_PatchTST_CTG_sl960_nc2_dm512_nh4_el6_df128_fc1_Exp<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Dataset loaded and preprocessed.
test set size: 3107
Accuracy: 0.76472481493402, AUC: 0.7440462952254714, Sensitivity: 0.5080731969860065, Specificity: 0.8741965105601469, PPV: 0.6327077747989276, NPV: 0.8064379500211775, F1: 0.5635820895522388
